{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c90d02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "# The code provided simulates the famous Monty Hall problem. This is a probability puzzle based on a game show, where a contestant is presented with three doors. Behind one door is a car (the prize), and behind the other two doors are goats (which are losing outcomes). After the contestant picks a door, the host, Monty Hall, opens one of the other two doors to reveal a goat. The contestant is then given the opportunity to either stick with their original choice or switch to the remaining unopened door.\n",
    "\n",
    "#This simulation is specifically designed to test the switch strategy — that is, whether switching doors after the host reveals a goat increases the contestant's chances of winning.\n",
    "\n",
    "#Let’s break down what the code is doing:\n",
    "\n",
    "#1. Setup\n",
    "#python\n",
    "#Copy code\n",
    "import numpy as np\n",
    "all_door_options = (1, 2, 3)  # tuple representing the three doors\n",
    "my_door_choice = 1  # contestant initially chooses door 1\n",
    "i_won = 0  # counter for the number of wins\n",
    "reps = 100000  # number of repetitions (simulations) to run\n",
    "all_door_options is a tuple representing the three doors.\n",
    "my_door_choice is initialized to 1 (the contestant always starts by picking door 1).\n",
    "i_won is initialized to 0 and will be used to count how many times the contestant wins (i.e., chooses the door with the car).\n",
    "reps is the number of times the simulation will be run (100,000 repetitions in this case).\n",
    "\n",
    "#2. Simulation Loop\n",
    "python\n",
    "Copy code\n",
    "for i in range(reps):\n",
    "This is a loop that will run 100,000 times to simulate many instances of the game.\n",
    "\n",
    "#3. Choosing the Winning Door\n",
    "python\n",
    "Copy code\n",
    "secret_winning_door = np.random.choice(all_door_options)\n",
    "In each iteration of the loop, the program randomly selects a \"winning\" door (the door with the car) using np.random.choice.\n",
    "\n",
    "#4. Removing the Winning Door from the List\n",
    "python\n",
    "Copy code\n",
    "all_door_options_list = list(all_door_options)\n",
    "all_door_options_list.remove(secret_winning_door)\n",
    "The tuple all_door_options is converted to a list, and the winning door (the car) is removed from this list. This step is important because the host will never reveal the door with the car.\n",
    "\n",
    "#5. Removing the Player's Initial Choice (if it’s Not the Winning Door)\n",
    "python\n",
    "Copy code\n",
    "try:\n",
    "    all_door_options_list.remove(my_door_choice)\n",
    "except:\n",
    "    pass\n",
    "The program then tries to remove the contestant’s initial choice (my_door_choice) from the list. If the initial choice was the winning door, it’s already removed, and this operation will raise an exception (which is caught and ignored by the try-except block).\n",
    "\n",
    "#6. Revealing a \"Goat\" Door\n",
    "python\n",
    "Copy code\n",
    "goat_door_reveal = np.random.choice(all_door_options_list)\n",
    "all_door_options_list.remove(goat_door_reveal)\n",
    "The host (Monty Hall) now reveals a door with a goat behind it. This is chosen randomly from the remaining options (all_door_options_list), which only contains doors with goats at this point. After revealing the \"goat\" door, it is also removed from the list.\n",
    "\n",
    "#7. Putting the Winning Door Back in the List\n",
    "python\n",
    "Copy code\n",
    "if secret_winning_door != my_door_choice:\n",
    "    all_door_options_list.append(secret_winning_door)\n",
    "If the contestant's initial choice wasn’t the winning door, the program adds the winning door back into the list of possible doors. This is necessary because the contestant will now have the option to switch their choice to the remaining door, which could be the winning door.\n",
    "\n",
    "#8. Switching Strategy\n",
    "python\n",
    "Copy code\n",
    "my_door_choice = all_door_options_list[0]\n",
    "The program automatically implements the switch strategy here. After the host reveals a goat, the contestant will always switch to the remaining unopened door. This means my_door_choice is updated to the last door left in all_door_options_list.\n",
    "\n",
    "#9. Checking if the Contestant Won\n",
    "python\n",
    "Copy code\n",
    "if my_door_choice == secret_winning_door:\n",
    "    i_won += 1\n",
    "After switching doors, the program checks if the contestant's new choice (my_door_choice) is the winning door. If so, the i_won counter is incremented by 1, meaning the contestant won that round.\n",
    "\n",
    "#10. Final Calculation\n",
    "python\n",
    "Copy code\n",
    "i_won/reps\n",
    "After running 100,000 simulations, the program calculates the fraction of times the contestant won by switching doors. This result should be approximately 2/3, because in the Monty Hall problem, switching gives the contestant a 66.67% chance of winning.\n",
    "\n",
    "#Summary of the Monty Hall Problem in this Code:\n",
    "#The contestant always starts by choosing door 1.\n",
    "#Monty Hall reveals a door with a goat behind it.\n",
    "#The contestant then switches their choice to the other unopened door.\n",
    "#The simulation tracks how often switching leads to a win.\n",
    "#Over a large number of repetitions (100,000), the result will demonstrate that the contestant has a better chance of winning (around 66.67%) if they always switch doors.\n",
    "#The simulation demonstrates that the strategy of switching doors significantly increases the chance of winning the prize compared to sticking with the original choice, which only has a 1/3 chance of winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "febe3218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winning probability by switching: 0.66602\n"
     ]
    }
   ],
   "source": [
    "#Q2 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "NUM_DOORS = (1, 2, 3)  # The three possible doors\n",
    "INITIAL_CHOICE = 1     # Contestant always starts by choosing door 1\n",
    "TOTAL_SIMULATIONS = 100000  # Number of repetitions\n",
    "wins = 0  # Counter for wins\n",
    "\n",
    "# Simulation loop\n",
    "for _ in range(TOTAL_SIMULATIONS):\n",
    "    # Randomly select the winning door\n",
    "    winning_door = np.random.choice(NUM_DOORS)\n",
    "    \n",
    "    # Remove the contestant's initial choice and the winning door from possible options\n",
    "    remaining_doors = [door for door in NUM_DOORS if door != winning_door and door != INITIAL_CHOICE]\n",
    "    \n",
    "    # Monty reveals a losing (goat) door from the remaining doors\n",
    "    revealed_goat = np.random.choice(remaining_doors)\n",
    "    \n",
    "    # The contestant switches to the remaining unopened door\n",
    "    switched_choice = [door for door in NUM_DOORS if door != revealed_goat and door != INITIAL_CHOICE][0]\n",
    "    \n",
    "    # Check if the contestant won by switching\n",
    "    if switched_choice == winning_door:\n",
    "        wins += 1\n",
    "\n",
    "# Calculate and print the probability of winning by switching\n",
    "winning_probability = wins / TOTAL_SIMULATIONS\n",
    "print(f\"Winning probability by switching: {winning_probability}\")\n",
    "\n",
    "\n",
    "#Key Changes:\n",
    "#Constants for Better Readability:\n",
    "\n",
    "#Instead of hardcoding the tuple of doors and the initial door choice multiple times, I defined NUM_DOORS and INITIAL_CHOICE at the beginning to make the code more readable and flexible.\n",
    "#The total number of simulations is also stored in TOTAL_SIMULATIONS to make it easier to adjust.\n",
    "#List Comprehensions:\n",
    "\n",
    "#I've used list comprehensions to filter out the remaining doors after the initial choice and the winning door are removed. This makes the code more concise and easier to understand, as the intention is clear at a glance.\n",
    "#Clearer Variable Names:\n",
    "\n",
    "#Changed variable names like secret_winning_door to winning_door for clarity.\n",
    "#all_door_options_list is replaced by remaining_doors, which directly communicates the purpose of the list.\n",
    "#Simplified Logic:\n",
    "\n",
    "#Removed unnecessary try-except block. By filtering with list comprehensions, there’s no need to handle the removal of the contestant’s door separately.\n",
    "#The \"swap\" logic is simplified using a list comprehension to directly pick the remaining unopened door.\n",
    "#Code Comparison Preferences:\n",
    "#Readability:\n",
    "\n",
    "#The refactored code is more concise and clearer because it reduces repetition and uses more descriptive variable names.\n",
    "#Defining constants at the top (like NUM_DOORS, INITIAL_CHOICE, and TOTAL_SIMULATIONS) makes the code easier to modify and maintain.\n",
    "#Explanation:\n",
    "\n",
    "#The refactored code reduces comments while keeping the logic self-explanatory. In Python, when code is clean and straightforward, excessive comments are often not necessary.\n",
    "#Using list comprehensions improves both performance and clarity, making it obvious that we're simply removing doors to reveal the correct choices.\n",
    "#Original Code Pros:\n",
    "\n",
    "#The original code might be useful for someone who is still learning basic programming concepts. It explicitly describes steps like removing doors one by one, which could help in understanding the underlying logic in detail.\n",
    "#More comments in the original version help beginners understand the reasoning behind each step, even though they slow down readability for more experienced developers.\n",
    "\n",
    "#In summary, the refactored version is clearer for intermediate users, while the original version gives more detailed steps, which can help beginners understand the problem better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3\n",
    "#Line-by-Line Comments:\n",
    "\n",
    "#import numpy as np: Imports the numpy library, which is used to randomly select a winning door and a revealed goat door in the simulation.\n",
    "\n",
    "#NUM_DOORS = (1, 2, 3): Defines the three possible doors the contestant can choose from in the game.\n",
    "\n",
    "#INITIAL_CHOICE = 1: The contestant always starts by choosing door 1, as a consistent initial strategy for the simulation.\n",
    "\n",
    "#TOTAL_SIMULATIONS = 100000: The simulation will run 100,000 times to ensure statistically significant results.\n",
    "\n",
    "#wins = 0: Initializes a counter to track how many times the contestant wins by switching doors.\n",
    "\n",
    "#for _ in range(TOTAL_SIMULATIONS):: Begins a loop that runs the simulation TOTAL_SIMULATIONS times (100,000 repetitions).\n",
    "\n",
    "#winning_door = np.random.choice(NUM_DOORS): Randomly selects one of the three doors to be the winning door (the door with the car behind it).\n",
    "\n",
    "#remaining_doors = [door for door in NUM_DOORS if door != winning_door and door != INITIAL_CHOICE]: Creates a list of doors excluding the contestant's initial choice and the winning door.\n",
    "\n",
    "#revealed_goat = np.random.choice(remaining_doors): Monty reveals a door that does not have the car behind it (one of the remaining doors).\n",
    "\n",
    "#switched_choice = [door for door in NUM_DOORS if door != revealed_goat and door != INITIAL_CHOICE][0]: The contestant switches their choice to the remaining unopened door.\n",
    "\n",
    "#if switched_choice == winning_door:: Checks if the door the contestant switched to is the winning door.\n",
    "\n",
    "#wins += 1: If the contestant wins by switching, the win counter is incremented.\n",
    "\n",
    "#winning_probability = wins / TOTAL_SIMULATIONS: Calculates the probability of winning by switching, based on how many times the contestant won out of the total number of simulations.\n",
    "\n",
    "#print(f\"Winning probability by switching: {winning_probability}\"): Prints the final result: the probability that the contestant wins by switching doors, which should be close to 66.67% (or 2/3).\n",
    " \n",
    "#Expected Output:\n",
    "    \n",
    "Winning probability by switching: 0.66678  # Example output, will be around 0.666\n",
    "\n",
    "#Summary:\n",
    "#This code demonstrates that switching doors in the Monty Hall problem leads to a significantly higher chance of winning, typically around 66.67%. The simulation confirms the counter-intuitive result that switching gives the contestant a better chance of winning than sticking with the original choice.\n",
    "\n",
    "#Chat history: In this conversation, we worked through the Monty Hall problem, a probability puzzle, focusing on improving the clarity and functionality of the simulation code. I provided a simplified and cleaned-up version of the original code, explained the purpose of each line, and ensured the code was verified to work with a final output. We also discussed preferences in readability and efficiency between the original and improved versions, concluding with a refactored version that improves both clarity and functionality while demonstrating that switching doors increases the chances of winning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a48df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4\n",
    "#Explanation of the \"Markovian ChatBot\" Code:\n",
    "#This code creates the framework for a Markovian ChatBot, which builds a Markov chain based on word sequences from a dataset (words). Here's a breakdown of how the code works and how it relates to a Markov Chain:\n",
    "\n",
    "#How It Works:\n",
    "#Markov Chain Overview:\n",
    "#A Markov Chain models systems where the probability of a future state (in this case, the next word) depends only on the current state (the current word). In a first-order Markov chain, the chatbot's next word is predicted based solely on the most recent word.\n",
    "\n",
    "#Word Usage Tracking:\n",
    "\n",
    "#The word_used dictionary counts how many times each word appears in the words list. This helps the bot learn how often each word is used.\n",
    "#Next Word Prediction:\n",
    "\n",
    "#The next_word dictionary maps each word to a dictionary of words that can follow it. This captures the frequencies of how often certain words follow each other.\n",
    "#For example, if \"hello\" is followed by \"world\" and \"chatbot\" in the input data, the bot will know that after \"hello,\" it might suggest \"world\" or \"chatbot,\" based on how frequently each follows \"hello.\"\n",
    "\n",
    "#Markov Chain Construction:\n",
    "\n",
    "#The loop through words[:-1] processes each word in the list except the last one (since the last word has no word that follows it).\n",
    "#The program updates both word_used and next_word for each word and its successor, creating a simple model of word transitions.\n",
    "#Application and Relevance of Markovian ChatBots:\n",
    "#Markovian ChatBots like this one are foundational for simple, rule-based language models that generate text based on probabilities derived from previous word sequences. Though less sophisticated than modern AI chatbots like GPT-3, these bots can still be useful in various contexts:\n",
    "\n",
    "#Text Generation:\n",
    "\n",
    "#These bots can generate text based on input patterns. For example, if trained on a specific dataset (like Shakespeare's works), the bot could generate text in a style similar to the input data.\n",
    "#Conversational Systems:\n",
    "\n",
    "#Early chatbots used simple Markov models to hold basic conversations. Given a prompt, the bot predicts the most probable next word based on its learned data.\n",
    "#Predictive Typing:\n",
    "\n",
    "#Applications like predictive text on smartphones or autocomplete features in search engines use Markov-like algorithms to predict the next word a user might type.\n",
    "#Games and Entertainment:\n",
    "\n",
    "#Markovian models can be used to create NPC dialogue in video games, where characters respond to player inputs based on predefined patterns.\n",
    "#Interacting with the ChatBot Session:\n",
    "#To demonstrate the chatbot's functionality, you would typically interact with it by feeding it text data (words) and then allowing it to predict or generate responses based on the patterns it has learned.\n",
    "\n",
    "#For example, after training the chatbot on a dataset, you could provide an input word, and the bot would generate the next word based on the most frequent sequences it has seen. Here’s how you could extend the code to simulate interaction:\n",
    "# Example: user inputs a word, and the bot responds with the most likely next word\n",
    "user_input = \"hello\"  # This can be dynamic input from a user\n",
    "\n",
    "if user_input in next_word:\n",
    "    # Find the most frequent next word\n",
    "    possible_next_words = next_word[user_input]\n",
    "    most_likely_next_word = max(possible_next_words, key=possible_next_words.get)\n",
    "    print(f\"Bot response: {most_likely_next_word}\")\n",
    "else:\n",
    "    print(\"Bot response: Sorry, I don't know what comes next.\")\n",
    "\n",
    "#In this example, if the word \"hello\" was followed by \"world\" several times in the training data, the bot would respond with \"world.\"\n",
    "\n",
    "#Summary:\n",
    "#This basic Markovian ChatBot code builds a first-order Markov chain to predict the next word in a conversation or text generation process. Though it doesn’t consider context or grammar like more advanced models, it’s an essential building block for understanding how early chatbots worked and how probability-based text generation systems function.\n",
    "\n",
    "#Markovian models are relevant for tasks like predictive typing, basic conversational agents, and generating text in a specific style based on input data.\n",
    "\n",
    "#Chat History: In this session, we explored the workings of a \"Markovian ChatBot\" based on a first-order Markov chain. The code tracks how often each word appears and what words typically follow each other. We discussed how the bot learns from word sequences and predicts the next word based on past data. Applications of such models include text generation, predictive typing, and basic conversational agents. Finally, I provided an example of how you could interact with the bot, simulating a simple conversation by predicting the next word in a sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5\n",
    "#(1)\n",
    "#Summary:\n",
    "#This extension upgrades the original first-order Markov chain to a second-order model, providing the chatbot with more context by using two words to predict the next one. As a result, the chatbot becomes better at generating more coherent and contextually relevant responses. This is a step forward in building more advanced conversational systems and improving text prediction.\n",
    "\n",
    "#Summary of Key Differences and New Functionality:\n",
    "#Character-Specific Word Sequences:\n",
    "\n",
    "#The chatbot now tracks word sequences based on individual characters in the dataset. This means it can generate responses that mimic each character's speaking style or language patterns.\n",
    "#Second-Order Markov Chain:\n",
    "\n",
    "#Like in Extension #1, this code uses a second-order Markov chain, where the bot predicts the next word based on the two preceding words. However, it now does so per character.\n",
    "#Customization by Character:\n",
    "\n",
    "#When the chatbot interacts with a user, it can generate different responses depending on the selected character, allowing for customized dialogue generation based on who is \"speaking.\"\n",
    "#Example:\n",
    "#If you have a dataset with characters \"Aang\" and \"Zuko,\" this chatbot can learn their unique speech patterns and generate text that reflects each character’s typical word usage. If \"Aang\" often says \"I'm ready\" and \"Zuko\" says \"I'm angry,\" the bot would reflect these patterns depending on which character is speaking.\n",
    "\n",
    "#Applications of Character-Specific Markov Chains:\n",
    "#Character-Based Chatbots:\n",
    "\n",
    "#This model is useful for creating chatbots that simulate dialogue for specific fictional or real-life characters, allowing users to interact with chatbots that \"talk\" like those characters.\n",
    "#Story Generation:\n",
    "\n",
    "#By learning distinct language patterns for each character, this extension could be used in creative applications like generating stories or dialogues where each character maintains a unique voice.\n",
    "#Games and Simulations:\n",
    "\n",
    "#In video games or simulations, this technique can generate character-specific dialogue, enriching the user experience by making characters behave and speak in ways consistent with their personalities.\n",
    "#This extension represents a step toward building more advanced conversational models that can reflect the individual styles of different speakers or characters.\n",
    "\n",
    "\n",
    "#(2)\n",
    "#Let’s go into more detail on how Extension 1 and Extension 2 work and what they accomplish on top of the original first-order Markov chain. Both extensions aim to enhance the chatbot’s ability to model and predict word sequences, but they do so in different ways. Let’s break them down.\n",
    "\n",
    "#Extension 1: Moving from First-Order to Second-Order Markov Chain\n",
    "#What it does:\n",
    "#In Extension 1, the chatbot shifts from a first-order Markov chain to a second-order Markov chain. This means that instead of predicting the next word based on just one preceding word, the bot now looks at two consecutive words to predict the third word. This adds more context, making predictions more accurate and context-aware.\n",
    "\n",
    "#Code Breakdown:\n",
    "word_used2 = defaultdict(int)  # Tracks how many times each two-word sequence is used\n",
    "next_word2 = defaultdict(lambda: defaultdict(int))  # Tracks how often a word follows each two-word sequence\n",
    "\n",
    "for i, word in enumerate(words[:-2]):  # Loop through the list of words, excluding the last two\n",
    "    word_used2[word + ' ' + words[i+1]] += 1  # Increment count for this two-word sequence\n",
    "    next_word2[word + ' ' + words[i+1]][words[i+2]] += 1  # Increment count for the word that follows this sequence\n",
    "\n",
    "#Key Details:\n",
    "#Tracking Pairs of Words:\n",
    "\n",
    "#In the original code, the bot only tracks how often individual words appear and what word comes next. In this extension, the bot tracks two-word sequences. For example, instead of just \"hello,\" it tracks \"hello world.\"\n",
    "\n",
    "#The variable word_used2 keeps count of how many times a specific two-word sequence appears.\n",
    "\n",
    "#Predicting the Next Word:\n",
    "\n",
    "#The bot now predicts the next word based on the last two words. The dictionary next_word2 stores the count of how often a specific third word follows each two-word sequence.\n",
    "\n",
    "#For example, if \"I am\" is followed by \"happy\" or \"sad\" in the input data, the bot will store both options with their respective frequencies in next_word2[\"I am\"][\"happy\"] and next_word2[\"I am\"][\"sad\"].\n",
    "\n",
    "#How it works:\n",
    "#The bot looks at two consecutive words in the input text. For example, given \"I am happy,\" the pair \"I am\" is stored, and \"happy\" is recorded as the next word.\n",
    "#When asked to generate text, the bot will use the two most recent words in the conversation to predict what the next word should be. This gives the bot more context, which makes its responses more coherent than a first-order model, which only looks at the most recent single word.\n",
    "#Example:\n",
    "#For the input words = [\"I\", \"am\", \"happy\", \"I\", \"am\", \"sad\"], the bot builds the following:\n",
    "\n",
    "#word_used2 = {\"I am\": 2}: This two-word sequence appears twice.\n",
    "#next_word2 = {\"I am\": {\"happy\": 1, \"sad\": 1}}: After \"I am,\" the bot has learned that \"happy\" and \"sad\" can both follow with equal probability.\n",
    "#Summary:\n",
    "#Extension 1 makes the chatbot more sophisticated by taking two previous words into account, rather than just one. This is a second-order Markov chain, where the next word is predicted based on the last two words instead of only one. The extra context improves the chatbot’s ability to generate more coherent text and mimic more natural speech patterns.\n",
    "\n",
    "#Extension 2: Character-Specific Markov Chain\n",
    "#What it does:\n",
    "#Extension 2 takes the Markov chain model a step further by incorporating character-specific word sequences. Instead of building a single model for all text, the chatbot now builds a separate Markov chain for each character in the dataset. This means that each character will have their own word usage and prediction model, which allows the bot to generate text specific to each character’s speech patterns.\n",
    "\n",
    "#Code Breakdown:\n",
    "#Preprocessing the Character Data:\n",
    "characters = Counter(\"\\n\" + avatar.character.str.upper().str.replace(' ','.') + \":\")\n",
    "\n",
    "#characters Counter: This line processes the character column from the avatar dataset. It converts each character's name to uppercase and replaces spaces with dots (.). The result is a count of how many times each character appears in the dataset.\n",
    "\n",
    "#Nested Dictionary Structure:\n",
    "nested_dict = lambda: defaultdict(nested_dict)  # Recursive dictionary structure\n",
    "\n",
    "word_used2C = nested_dict()  # Tracks word pair frequencies for each character\n",
    "next_word2C = nested_dict()  # Tracks next word frequencies for each character\n",
    "\n",
    "#nested_dict: This lambda function creates a recursive defaultdict, which allows us to build deep dictionary structures easily. This structure allows us to keep track of word usage and transitions per character.\n",
    "\n",
    "#Main Loop:\n",
    "for i, word in enumerate(words[:-2]):\n",
    "    if word in characters:  # If the word matches a character's name\n",
    "        character = word  # Set the current character\n",
    "        \n",
    "    # Initialize word usage for the character if not already initialized\n",
    "    if character not in word_used2C:\n",
    "        word_used2C[character] = dict()\n",
    "        \n",
    "    # Track the two-word sequence for the current character\n",
    "    if word+' '+words[i+1] not in word_used2C[character]:\n",
    "        word_used2C[character][word+' '+words[i+1]] = 0\n",
    "    word_used2C[character][word+' '+words[i+1]] += 1\n",
    "    \n",
    "    # Track the word that follows the two-word sequence for the current character\n",
    "    if character not in next_word2C:\n",
    "        next_word2C[character] = dict()\n",
    "    if word+' '+words[i+1] not in next_word2C[character]:\n",
    "        next_word2C[character][word+' '+words[i+1]] = dict()\n",
    "    if words[i+2] not in next_word2C[character][word+' '+words[i+1]]:\n",
    "        next_word2C[character][word+' '+words[i+1]][words[i+2]] = 0\n",
    "    next_word2C[character][word+' '+words[i+1]][words[i+2]] += 1\n",
    "\n",
    "#Track Words for Each Character:\n",
    "#In the loop, the code checks if the current word matches a character’s name (from the characters dataset). If so, it assigns this as the active character.\n",
    "\n",
    "#For each character, the bot then tracks word pairs and their corresponding next words. This is done similarly to Extension 1, but the data is now specific to each character.\n",
    "\n",
    "#How it works:\n",
    "#The bot now builds separate Markov chains for each character in the dataset. When generating text, it uses the character-specific chain to predict the next word based on what that character typically says.\n",
    "\n",
    "#For example, if the bot is interacting with a character named \"Aang,\" it will only use the word sequences and patterns associated with \"Aang\" to generate responses.\n",
    "\n",
    "#Example:\n",
    "#If we have characters \"Aang\" and \"Zuko\" in the dataset, and their speech patterns are different:\n",
    "\n",
    "#For \"Aang,\" the bot may learn that \"I am\" is followed by \"happy\" most of the time.\n",
    "#For \"Zuko,\" it may learn that \"I am\" is followed by \"angry.\"\n",
    "#Now, depending on which character is speaking, the chatbot will generate responses that reflect their specific language patterns.\n",
    "\n",
    "#Summary:\n",
    "#Extension 2 introduces character-specific Markov chains, allowing the chatbot to learn and predict word sequences for each individual character in a dataset. This makes the chatbot more versatile, as it can now generate text that reflects the unique speech patterns of different characters, rather than a generic model for all text. This is useful in applications like creating chatbots that simulate multiple characters in games, stories, or educational platforms.\n",
    "\n",
    "#Chatbot history: In this session, we explored the workings of a \"Markovian ChatBot\" and its two extensions.\n",
    "\n",
    "#Original Markovian ChatBot: The initial code built a first-order Markov chain, where the chatbot predicts the next word based on the current word by learning word transitions from a dataset.\n",
    "\n",
    "#Extension 1: We discussed moving to a second-order Markov chain, where the chatbot now predicts the next word based on the previous two words, providing more context for text generation and improving coherence.\n",
    "\n",
    "#Extension 2: This extension introduced character-specific Markov chains, where the bot builds separate Markov chains for each character in a dataset. The chatbot generates responses based on the unique word patterns of individual characters, allowing for more personalized and varied text generation.\n",
    "\n",
    "#Overall, the extensions make the chatbot more sophisticated by providing better context (Extension 1) and character-specific responses (Extension 2).\n",
    "\n",
    "#Link: https://chatgpt.com/share/66ec4ee0-1378-800a-bff1-2ec3de517e7f\n",
    "\n",
    "\n",
    "#(3)\n",
    "#This code is part of a chatbot implementation that uses a Markov Chain approach to generate text based on a dataset (presumably a script or dialogue dataset), where each character's lines are treated as individual sequences of words. Here's a breakdown of what it does:\n",
    "\n",
    "#1. Importing Libraries:\n",
    "#collections.Counter: This is used to count the occurrence of elements in a list or iterable.\n",
    "#collections.defaultdict: This is used to create dictionaries with default types, allowing nested dictionary structures without explicitly checking if a key exists.\n",
    "#2. Defining the Characters:\n",
    "characters = Counter(\"\\n\"+ avatar.character.str.upper().str.replace(' ','.')+\":\")\n",
    "\n",
    "#avatar.character represents a column from the avatar dataset, presumably containing character names.\n",
    "#The Counter object is created to count the frequency of each character. Here's the breakdown of transformations:\n",
    "#.str.upper(): Converts character names to uppercase.\n",
    "#.str.replace(' ', '.'): Replaces spaces in the character names with dots (.) to create a consistent format.\n",
    "#Counter counts occurrences of each character in this transformed format.\n",
    "#3. Creating Nested Dictionaries:\n",
    "nested_dict = lambda: defaultdict(nested_dict)\n",
    "word_used2C = nested_dict()\n",
    "next_word2C = nested_dict()\n",
    "\n",
    "#nested_dict is a recursive function that creates a nested defaultdict structure.\n",
    "#word_used2C and next_word2C are two nested dictionaries:\n",
    "#word_used2C tracks bigrams (two-word sequences) spoken by each character.\n",
    "#next_word2C tracks trigrams (three-word sequences) spoken by each character.\n",
    "#4. Processing the Text:\n",
    "for i, word in enumerate(words[:-2]):\n",
    "    if word in characters:\n",
    "        character = word\n",
    "\n",
    "#This loop processes the text data (assumed to be a sequence of words).\n",
    "#words[:-2] loops over all words in the dataset except the last two.\n",
    "#For each word, the code checks if it matches a character's name (using the characters Counter). When a match is found, the variable character is set to the corresponding character.\n",
    "#5. Populating word_used2C Dictionary:\n",
    "if word+' '+words[i+1] not in word_used2C[character]:\n",
    "    word_used2C[character][word+' '+words[i+1]] = 0\n",
    "word_used2C[character][word+' '+words[i+1]] += 1\n",
    "\n",
    "#his section constructs bigrams (two-word combinations) using word and words[i+1] for each character.\n",
    "#If a bigram for the character doesn't exist, it's initialized to 0.\n",
    "#The count for each bigram is incremented.\n",
    "#6. Populating next_word2C Dictionary:\n",
    "if word+' '+words[i+1] not in next_word2C[character]:\n",
    "    next_word2C[character][word+' '+words[i+1]] = dict()\n",
    "if words[i+2] not in next_word2C[character][word+' '+words[i+1]]:\n",
    "    next_word2C[character][word+' '+words[i+1]][words[i+2]] = 0\n",
    "next_word2C[character][word+' '+words[i+1]][words[i+2]] += 1\n",
    "\n",
    "\n",
    "#This section constructs trigrams (three-word sequences) using word, words[i+1], and words[i+2].\n",
    "#Similar to the bigram construction, it ensures that the trigram for the current character is initialized and updates its count.\n",
    "#Summary:\n",
    "#Goal: The code is designed to build a Markov chain for each character's speech, which can then be used to predict or generate text sequences.\n",
    "#word_used2C: Tracks bigram counts for each character.\n",
    "#next_word2C: Tracks trigram counts for each character, where the first two words are followed by a possible third word.\n",
    "#Purpose: The resulting data structures can be used to generate character-specific dialogue by probabilistically choosing the next word in a sequence based on previously observed patterns.\n",
    "\n",
    "#Chatbot history: In this session, you shared a piece of code related to a Markovian chatbot. I explained how the code works by breaking it down into key steps:\n",
    "\n",
    "#Character Identification: The code processes the avatar dataset to extract character names by transforming them to uppercase and replacing spaces with dots, then counting the occurrences of each character.\n",
    "\n",
    "#Markov Chain Construction: The code builds two nested dictionaries:\n",
    "\n",
    "#word_used2C: Tracks the frequency of bigrams (two-word sequences) spoken by each character.\n",
    "#next_word2C: Tracks trigrams (three-word sequences), mapping pairs of words to the possible third word.\n",
    "#Purpose: This structure allows the chatbot to model character-specific speech patterns, enabling the generation of new dialogue based on observed word sequences from the dataset.\n",
    "#You asked for a summary of our session, and this is the condensed version!\n",
    "\n",
    "#Link: https://chatgpt.com/share/66ec4f45-751c-800a-b7a3-2eba3d05c1ed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dcf405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6\n",
    "#(1)\n",
    "#chatgpt was able to solve my problem very quickly and give very helpful advice. Every time I sent gpt a piece of code it clearly explained what the code was and what it was doing.\n",
    "\n",
    "#(2)\n",
    "#I think for the most part it works well and gpt answers my questions accurately, but the only time it's more frustrating is when I don't give gpt full background information and gpt's explanations become less reliable. For example if I don't give it the first two codes of extension and instead just give gpt the code for Extension2, it becomes less accurate.\n",
    "\n",
    "#(3)\n",
    "#gpt is pretty much spot on for code interpretation, but for generating code if I don't have any templates I just ask it to generate a code for me, it probably won't give me the code I want correctly. And if I have a performance code for gpt to help me optimize or for gpt to help me explain it, it's better and more accurate to use in that area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59a73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7\n",
    "#After using chatgpt many times in these two assignments, I deeply felt the power of ai intelligence, chatgpt basically every time as long as I can provide enough information and let it help me to answer the question when it can be very accurate to explain and give me more than one solution. For example, from the last assignment we compared Chatgpt with other chatbots and search engines to see which one worked best, and it was clear that Chatgpt was the best, both in terms of writing code, correcting code errors, and interpreting what the code was doing, and it worked far better than the other tools. And I think chatgpt has helped me explain a lot of assignments I didn't understand in the past two weeks of my study.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8\n",
    "#(1)\n",
    "#Relevance of Learning and Adaptability, Communication, Coding, and Statistics and Data Analysis as Skills in the Modern World (Particularly in the Context of Data Science)\n",
    "#In the modern workforce, and especially within the data science industry, the combination of learning and adaptability, communication, coding, and statistics and data analysis represents a powerful suite of skills. These competencies not only improve career prospects but also enable individuals to navigate and thrive in industries driven by rapid technological change, data, and automation.\n",
    "\n",
    "#1. Learning and Adaptability\n",
    "#Relevance: The modern world is characterized by rapid technological advancements and evolving industry landscapes, especially in fields like data science, artificial intelligence, and machine learning. Professionals must stay current with new tools, techniques, and methodologies. The ability to learn quickly and adapt to new situations is essential.\n",
    "\n",
    "#In Data Science:\n",
    "\n",
    "#Rapid evolution of tools: Data scientists need to keep up with emerging programming languages (like Python and R), tools (TensorFlow, PyTorch, etc.), and cloud-based platforms (AWS, Azure).\n",
    "#Problem-solving: Data science involves solving complex and often ambiguous problems. Adaptability allows professionals to shift approaches and methodologies when necessary.\n",
    "#Continuous learning: New algorithms, research papers, and best practices are constantly being developed. A mindset of lifelong learning is crucial to staying competitive in this field.\n",
    "#Career Opportunities:\n",
    "\n",
    "#Highly adaptable professionals are sought after by companies facing dynamic market conditions.\n",
    "#Employers value individuals who can adjust quickly to new responsibilities, technologies, or industries, as data science roles can span across finance, healthcare, marketing, and more.\n",
    "#2. Communication\n",
    "#Relevance: Strong communication skills are often underrated but critically important, particularly in fields like data science where professionals must work with non-technical stakeholders. Being able to convey complex insights in a clear, actionable way is crucial for driving data-driven decision-making.\n",
    "\n",
    "#In Data Science:\n",
    "\n",
    "#Interpreting data: Data scientists frequently work with large datasets, and their findings need to be understood by business executives, product teams, or clients who may not have technical expertise.\n",
    "#Collaboration: Data science projects often involve cross-functional teams including engineers, analysts, and business leaders. Clear communication facilitates better collaboration and project outcomes.\n",
    "#Storytelling with data: Presenting insights through data visualization tools like Tableau or Power BI requires not only technical proficiency but also the ability to create a compelling narrative that aligns with business goals.\n",
    "#Career Opportunities:\n",
    "\n",
    "#Data scientists who excel at communication are more likely to move into leadership or managerial roles, bridging the gap between technical teams and executive decision-makers.\n",
    "#Strong communication is particularly valued in client-facing roles, such as consulting or as a data product manager, where explaining complex models or findings to clients is a key part of the job.\n",
    "#3. Coding\n",
    "#Relevance: Coding is foundational in data science and is increasingly becoming a general-purpose skill across various industries. Proficiency in coding enables data scientists to manipulate large datasets, develop algorithms, and automate processes.\n",
    "\n",
    "#In Data Science:\n",
    "\n",
    "#Programming languages: Python, R, SQL, and Java are commonly used in data science for data manipulation, analysis, and building machine learning models.\n",
    "#Automation and efficiency: Data scientists need to automate repetitive tasks like data cleaning or model training. Coding enables them to do this efficiently, freeing time for more strategic work.\n",
    "#Custom model development: Many off-the-shelf machine learning models may not fully address a specific business need. Coding allows data scientists to create and fine-tune custom algorithms for unique challenges.\n",
    "#Career Opportunities:\n",
    "\n",
    "#Advanced coding skills make data scientists more versatile, opening up opportunities in areas like machine learning engineering, AI development, and software engineering.\n",
    "#Data professionals with coding expertise can more easily transition into technical roles like data engineers or systems architects, which are often in high demand.\n",
    "#4. Statistics and Data Analysis\n",
    "#Relevance: At the heart of data science lies statistics and data analysis. These skills are essential for interpreting data, identifying trends, and making data-driven decisions. A deep understanding of statistics is fundamental for building reliable models, interpreting data correctly, and deriving actionable insights.\n",
    "\n",
    "#In Data Science:\n",
    "\n",
    "#Understanding patterns and correlations: Statistical techniques like regression analysis, hypothesis testing, and probability theory help data scientists identify significant trends and relationships in datasets.\n",
    "#Model evaluation: Evaluating the performance of machine learning models requires a sound understanding of metrics like precision, recall, and F1 score, which are grounded in statistics.\n",
    "#Data wrangling and preprocessing: Data is often messy or incomplete, and statistical methods help in cleaning, filling missing values, and normalizing data to prepare it for analysis or model-building.\n",
    "#Career Opportunities:\n",
    "\n",
    "#Expertise in statistics and data analysis is essential for roles like data analyst, quantitative researcher, and applied statistician.\n",
    "#Companies in fields like finance, healthcare, and e-commerce actively seek professionals with strong statistical backgrounds to guide critical decisions in risk management, pricing, and customer insights.\n",
    "#Conclusion: Synergy of Skills for Data Science Careers\n",
    "#Learning and Adaptability enable professionals to stay relevant in a fast-evolving field.\n",
    "#Communication skills allow data scientists to make their work accessible and valuable to non-technical stakeholders.\n",
    "#Coding proficiency provides the technical backbone necessary to work with data at scale and develop algorithms.\n",
    "#Statistics and Data Analysis form the analytical foundation upon which data-driven insights are built.\n",
    "#Together, these skills create a well-rounded professional capable of excelling in the data science industry and beyond. Companies increasingly demand individuals who not only possess technical know-how but also have the ability to learn, adapt, communicate, and think critically in a data-driven world.\n",
    "\n",
    "\n",
    "#(2)\n",
    "#Yes, it is definitely possible to become a statistician or data scientist in the future, even if you currently don't have experience in coding or statistics. Learning these skills step by step, using resources like chatbots, online courses, tutorials, and hands-on practice, can help you build the expertise you need. The journey may take time and effort, but with dedication, you can certainly succeed. Below is a breakdown of the most important skills you will need to work in these industries, along with an approach to start learning them.\n",
    "\n",
    "#Most Important Skills for a Statistician or Data Scientist\n",
    "#1. Mathematics (especially Statistics)\n",
    "#Importance: Statistics forms the backbone of data science. Understanding core statistical concepts is critical for analyzing data, developing models, and deriving insights.\n",
    "#Key Areas:\n",
    "#Descriptive statistics: mean, median, variance, etc.\n",
    "#Inferential statistics: hypothesis testing, confidence intervals, p-values\n",
    "#Probability theory: distributions (normal, binomial, etc.)\n",
    "#Regression analysis (linear and logistic regression)\n",
    "#Experimental design and sampling methods\n",
    "#How to Learn:\n",
    "#Start with beginner-level books or online resources in statistics (e.g., \"Statistics for Dummies\").\n",
    "#Platforms like Khan Academy or Coursera offer courses on basic and advanced statistics.\n",
    "#Use online calculators and simulations to practice understanding statistical distributions and tests.\n",
    "#2. Programming and Coding\n",
    "#Importance: Coding is crucial for manipulating, analyzing, and visualizing large datasets, as well as for automating repetitive tasks. In data science, programming is often used for statistical modeling and implementing machine learning algorithms.\n",
    "#Key Languages:\n",
    "#Python: Most popular for data science due to its simplicity and rich ecosystem of libraries (e.g., Pandas, NumPy, Scikit-learn, TensorFlow).\n",
    "#R: Another popular language, especially for statistical analysis and visualization.\n",
    "#SQL: For querying and managing databases.\n",
    "#How to Learn:\n",
    "#Start with introductory courses in Python or R on platforms like Codecademy, Coursera, or DataCamp.\n",
    "#Focus on data manipulation libraries (e.g., Pandas in Python) and simple exercises.\n",
    "#As you progress, explore online coding exercises or challenges (e.g., LeetCode or Kaggle) to build your problem-solving skills.\n",
    "#3. Data Wrangling and Preprocessing\n",
    "#Importance: Data is often messy and unstructured. Data scientists spend a significant amount of time cleaning, transforming, and preparing data for analysis.\n",
    "#Key Techniques:\n",
    "#Handling missing data\n",
    "#Normalizing and scaling data\n",
    "#Transforming categorical variables\n",
    "#Feature engineering\n",
    "#How to Learn:\n",
    "#Practice on real-world datasets (available on Kaggle or other open-data platforms).\n",
    "#Follow tutorials that focus on cleaning and preprocessing data, using libraries like Pandas in Python.\n",
    "#4. Data Visualization\n",
    "#Importance: Visualizing data is critical for both analysis and communication. Being able to present complex insights through clear graphs and charts helps non-technical stakeholders understand the results.\n",
    "#Key Tools:\n",
    "#Matplotlib and Seaborn (Python libraries) for custom visualizations.\n",
    "#Tableau or Power BI for creating interactive dashboards.\n",
    "#How to Learn:\n",
    "#Start with simple plotting techniques (e.g., bar charts, scatter plots) using Matplotlib.\n",
    "#As you progress, try creating more complex visualizations (e.g., heatmaps, interactive dashboards) with tools like Tableau.\n",
    "#5. Machine Learning (Optional for Statisticians, Important for Data Scientists)\n",
    "#Importance: Machine learning algorithms are used in data science to make predictions and uncover patterns in data. While a strong background in statistics is important for understanding these algorithms, machine learning is more technical and requires coding.\n",
    "#Key Concepts:\n",
    "#Supervised learning: regression, classification\n",
    "#Unsupervised learning: clustering, dimensionality reduction\n",
    "#Neural networks and deep learning (for advanced roles)\n",
    "#How to Learn:\n",
    "#Begin with high-level machine learning courses (e.g., Andrew Ng’s course on Coursera).\n",
    "#Focus on common algorithms like decision trees, random forests, k-means clustering, and linear regression.\n",
    "#Use libraries like Scikit-learn to implement basic machine learning models.\n",
    "#6. Critical Thinking and Problem-Solving\n",
    "#Importance: Data science is fundamentally about solving real-world problems using data. You’ll need to think critically about how to approach these problems, ask the right questions, and interpret the results correctly.\n",
    "#How to Develop:\n",
    "#Engage in projects where you can apply your skills to practical problems.\n",
    "#Study case studies of how data science is used in industries like healthcare, finance, or marketing.\n",
    "#Work on open datasets from Kaggle to develop real-world problem-solving skills.\n",
    "#7. Domain Knowledge\n",
    "#Importance: Understanding the specific context of the industry you’re working in (e.g., healthcare, finance, marketing) is important for applying statistical and data science techniques effectively.\n",
    "#How to Develop:\n",
    "#Read articles and research papers about the industry you’re interested in.\n",
    "#As you practice, focus on industry-specific projects or challenges that use relevant datasets.\n",
    "#How to Start Learning:\n",
    "#Step 1: Build a Foundation in Math and Statistics\n",
    "\n",
    "#Start with free or low-cost online courses that teach basic statistics.\n",
    "#Study concepts like mean, median, variance, regression, and probability theory.\n",
    "#Step 2: Learn Programming (Python or R)\n",
    "\n",
    "#Begin with introductory coding courses on platforms like Codecademy or Coursera.\n",
    "#Practice basic tasks like loading, cleaning, and manipulating data using Pandas (Python) or dplyr (R).\n",
    "#Step 3: Practice on Real-World Datasets\n",
    "\n",
    "#Use open datasets from Kaggle, UCI Machine Learning Repository, or government data portals to practice.\n",
    "#Work through data analysis problems step-by-step, cleaning data, and applying statistical models.\n",
    "#Step 4: Master Data Visualization\n",
    "\n",
    "#Learn basic plotting techniques in Python (Matplotlib, Seaborn) or R (ggplot2).\n",
    "#Experiment with interactive visualizations using Tableau or Power BI.\n",
    "#Step 5: Learn Machine Learning (for Data Science Focus)\n",
    "\n",
    "#Once you’re comfortable with statistics and programming, start exploring machine learning algorithms like linear regression, decision trees, and k-means clustering.\n",
    "#Step 6: Build Projects\n",
    "\n",
    "#Create data science or statistics projects for your portfolio (e.g., data exploration, visualization dashboards, predictive models).\n",
    "#Share your work on GitHub or Kaggle to demonstrate your skills to potential employers.\n",
    "#Continuous Learning Through Chatbot Assistance\n",
    "#A chatbot can:\n",
    "\n",
    "#Help explain concepts you're stuck on.\n",
    "#Provide code snippets and examples.\n",
    "#Guide you through common problems or exercises.\n",
    "#Suggest resources or tutorials.\n",
    "#Help troubleshoot coding or statistical issues as you practice.\n",
    "#While you may not become a statistician or data scientist solely through a chatbot, it can be a very helpful tool alongside courses, books, and hands-on projects. Ultimately, consistent practice, problem-solving, and learning from feedback will lead you to success in these fields.\n",
    "\n",
    "\n",
    "#(3)\n",
    "#Chatgpt history: Here's a summary of our discussions so far:\n",
    "\n",
    "#Core Skills for the statistician and Data Science:\n",
    "\n",
    "#We discussed the importance of four key skills: learning and adaptability, communication, coding, and statistics and data analysis, particularly in the context of the data science industry.\n",
    "#Learning and Adaptability help professionals keep up with rapid changes in tools and methodologies, essential for success in dynamic fields like data science.\n",
    "#Communication is critical for conveying complex data insights to non-technical stakeholders and collaborating across teams.\n",
    "#Coding is foundational for working with data, building models, and automating tasks, with Python and R being the most commonly used languages.\n",
    "#Statistics and Data Analysis form the backbone of data-driven decision-making, helping to interpret data, identify patterns, and evaluate models.\n",
    "#Starting as a Beginner in Data Science/Statistics:\n",
    "\n",
    "#You asked about starting a career in statistics or data science without prior experience in coding or statistics.\n",
    "#We outlined the most important skills to develop: mathematics (especially statistics), programming (Python, R, SQL), data wrangling, data visualization, machine learning, critical thinking, and domain knowledge.\n",
    "#We broke down a learning path:\n",
    "#Start with basic math and statistics.\n",
    "#Learn programming (Python/R) with a focus on data manipulation.\n",
    "#Work with real-world datasets and practice data cleaning and visualization.\n",
    "#Explore machine learning once you’ve built a foundation.\n",
    "#Apply your skills to real-world projects and continuously practice problem-solving.\n",
    "#Using Chatbots for Learning:\n",
    "\n",
    "#We discussed how a chatbot can assist in your learning journey by providing code snippets, explanations of complex concepts, and troubleshooting help. However, you will also need other resources like courses, books, and hands-on projects to fully master the skills required for a career in data science or statistics.\n",
    "#In essence, our conversations focused on developing the foundational skills and the learning approach needed to transition into data science or statistics, starting from scratch and building towards practical applications.\n",
    "\n",
    "#Link:https://chatgpt.com/share/66ec59d8-e5c0-800a-bcff-9fccc7df953a\n",
    "\n",
    "\n",
    "#(4)\n",
    "#Although I used chatgpt in the above two questions to help me answer the questions and skills needed for a career as a data scientist or statistician, the truth is that I don't really want to be a data scientist or statistician, I want to work in an investment bank after graduation. I want to work in investment banking after graduation. I know that this career may not sound like it has anything to do with the courses I'm taking, but sta130 is a required course for me to get into the math and statistics program. I want to take math stats after my sophomore year and then get an internship every summer to try to bulk up my resume so that it will be more competitive with other competitors after graduation. I have two cousins who both graduated from uoft, one of them studied commerece and the other one studied mathathics, both of them work in investment banks, if I can graduate successfully, through my own hard work and the recommendation letter from my cousins, I will probably work in investment banks. But this is not my ultimate goal, my ultimate goal is to realize freedom, and the only way to realize freedom is to have endless money, that is to say I want to be a millionaire. So all the jobs including investment banking are just a process for me, and building up my contacts and knowledge during these processes is the main thing.At the end of the process, I would like to invest in a company with friends or cousins I know and then RUN BUSINESS.After making lots and lots of money in RUN BUSINESS, I will put the money in the bank or invest it in different companies to earn interest, so as to realize the use of money to make money, so that I can really realize my ultimate goal, freedom.\n",
    "\n",
    "\n",
    "#(5)\n",
    "#Chatgpt answered okay, but there were times when maybe the answer it gave wasn't that specific or complete. I need to keep asking for more details to get a complete answer. Most of the time chatgpt gives me gengeral answers, it gives list lots and lots of information and different solutions, but if I let chatgpt help answer become more easier and simpler after it has answered the question, its answers will be shorter and more efficient and precise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb40252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9\n",
    "#yes, and basically every time I do it, chatgpt has become an essential tool in my studies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
